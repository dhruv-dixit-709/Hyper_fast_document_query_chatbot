{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea869c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d17a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ SET YOUR TARGET BASE URL HERE\n",
    "BASE_URL = \"https://www.stevens.edu/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6753bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver():\n",
    "    options = Options()\n",
    "    options.add_argument('--headless=new')  # Use new headless mode\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    return webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbb852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_internal(link, base_netloc):\n",
    "    parsed = urlparse(link)\n",
    "    return parsed.netloc == '' or parsed.netloc == base_netloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84a901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_href(href):\n",
    "    # Avoid mailto:, tel:, javascript:, etc.\n",
    "    return href and not href.startswith(('mailto:', 'tel:', 'javascript:', '#'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea287c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_question(text):\n",
    "    return text.strip().endswith('?') or re.match(r'^(how|what|why|when|where|who|is|can|does|should|do|did)\\b', text.strip(), re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a1585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_qa_pairs(soup):\n",
    "    qa_pairs = []\n",
    "    seen = set()\n",
    "\n",
    "    for tag in soup.find_all(re.compile('^h[1-6]$')):\n",
    "        question = tag.get_text(strip=True)\n",
    "        if is_question(question) and question not in seen:\n",
    "            answer = ''\n",
    "            for sib in tag.find_next_siblings():\n",
    "                if sib.name and sib.name.startswith('h'):\n",
    "                    break\n",
    "                answer += sib.get_text(separator=\"\\n\", strip=True) + \"\\n\"\n",
    "            answer = answer.strip()\n",
    "            if answer:\n",
    "                qa_pairs.append({'Question': question, 'Answer': answer})\n",
    "                seen.add(question)\n",
    "\n",
    "    for detail in soup.find_all('details'):\n",
    "        summary = detail.find('summary')\n",
    "        if summary:\n",
    "            question = summary.get_text(strip=True)\n",
    "            if is_question(question) and question not in seen:\n",
    "                detail_copy = detail.encode_contents().decode()\n",
    "                soup_copy = BeautifulSoup(detail_copy, 'lxml')\n",
    "                soup_copy.find('summary').decompose()\n",
    "                answer = soup_copy.get_text(separator=\"\\n\", strip=True)\n",
    "                if answer:\n",
    "                    qa_pairs.append({'Question': question, 'Answer': answer})\n",
    "                    seen.add(question)\n",
    "\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61482c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_site(base_url):\n",
    "    driver = get_driver()\n",
    "    visited = set()\n",
    "    to_visit = [base_url]\n",
    "    base_netloc = urlparse(base_url).netloc\n",
    "    all_qas = []\n",
    "\n",
    "    while to_visit:\n",
    "        url = to_visit.pop(0)\n",
    "        parsed_url = urlparse(url)\n",
    "        clean_url = parsed_url._replace(fragment='').geturl()\n",
    "\n",
    "        if clean_url in visited:\n",
    "            continue\n",
    "        visited.add(clean_url)\n",
    "\n",
    "        try:\n",
    "            driver.get(clean_url)\n",
    "            time.sleep(1.5)\n",
    "            soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load {clean_url}: {e}\")\n",
    "            continue\n",
    "\n",
    "        qa = extract_qa_pairs(soup)\n",
    "        all_qas.extend(qa)\n",
    "        print(f\"‚úÖ {len(qa)} Q&A from: {clean_url}\")\n",
    "\n",
    "        for a in soup.find_all('a', href=True):\n",
    "            href = a['href'].split('#')[0].strip()\n",
    "            if not is_valid_href(href):\n",
    "                continue\n",
    "            absolute = urljoin(clean_url, href)\n",
    "            parsed = urlparse(absolute)\n",
    "            if is_internal(absolute, base_netloc):\n",
    "                norm_url = parsed._replace(fragment='').geturl()\n",
    "                if norm_url not in visited and norm_url not in to_visit:\n",
    "                    to_visit.append(norm_url)\n",
    "\n",
    "    driver.quit()\n",
    "    return all_qas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(f\"üîç Starting scrape from: {BASE_URL}\")\n",
    "    qa_data = crawl_site(BASE_URL)\n",
    "    with open(\"questions_answers.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(qa_data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"‚úÖ Done. {len(qa_data)} Q&A pairs saved to 'questions_answers.json'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
